{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6234e24-0a28-438f-b8af-32d68007fe55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3260b082-ceea-4eb8-808f-f97b50c0dede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30445592-e708-49ea-bccb-84b4de87cc79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_49</th>\n",
       "      <th>feature_50</th>\n",
       "      <th>feature_51</th>\n",
       "      <th>feature_52</th>\n",
       "      <th>feature_53</th>\n",
       "      <th>feature_54</th>\n",
       "      <th>feature_55</th>\n",
       "      <th>feature_56</th>\n",
       "      <th>feature_57</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.142</td>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.555</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.404</td>\n",
       "      <td>6</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.147</td>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4601 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0          0.00       0.64       0.64        0.0       0.32       0.00   \n",
       "1          0.21       0.28       0.50        0.0       0.14       0.28   \n",
       "2          0.06       0.00       0.71        0.0       1.23       0.19   \n",
       "3          0.00       0.00       0.00        0.0       0.63       0.00   \n",
       "4          0.00       0.00       0.00        0.0       0.63       0.00   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "4596       0.31       0.00       0.62        0.0       0.00       0.31   \n",
       "4597       0.00       0.00       0.00        0.0       0.00       0.00   \n",
       "4598       0.30       0.00       0.30        0.0       0.00       0.00   \n",
       "4599       0.96       0.00       0.00        0.0       0.32       0.00   \n",
       "4600       0.00       0.00       0.65        0.0       0.00       0.00   \n",
       "\n",
       "      feature_7  feature_8  feature_9  feature_10  ...  feature_49  \\\n",
       "0          0.00       0.00       0.00        0.00  ...       0.000   \n",
       "1          0.21       0.07       0.00        0.94  ...       0.000   \n",
       "2          0.19       0.12       0.64        0.25  ...       0.010   \n",
       "3          0.31       0.63       0.31        0.63  ...       0.000   \n",
       "4          0.31       0.63       0.31        0.63  ...       0.000   \n",
       "...         ...        ...        ...         ...  ...         ...   \n",
       "4596       0.00       0.00       0.00        0.00  ...       0.000   \n",
       "4597       0.00       0.00       0.00        0.00  ...       0.000   \n",
       "4598       0.00       0.00       0.00        0.00  ...       0.102   \n",
       "4599       0.00       0.00       0.00        0.00  ...       0.000   \n",
       "4600       0.00       0.00       0.00        0.00  ...       0.000   \n",
       "\n",
       "      feature_50  feature_51  feature_52  feature_53  feature_54  feature_55  \\\n",
       "0          0.000         0.0       0.778       0.000       0.000       3.756   \n",
       "1          0.132         0.0       0.372       0.180       0.048       5.114   \n",
       "2          0.143         0.0       0.276       0.184       0.010       9.821   \n",
       "3          0.137         0.0       0.137       0.000       0.000       3.537   \n",
       "4          0.135         0.0       0.135       0.000       0.000       3.537   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "4596       0.232         0.0       0.000       0.000       0.000       1.142   \n",
       "4597       0.000         0.0       0.353       0.000       0.000       1.555   \n",
       "4598       0.718         0.0       0.000       0.000       0.000       1.404   \n",
       "4599       0.057         0.0       0.000       0.000       0.000       1.147   \n",
       "4600       0.000         0.0       0.125       0.000       0.000       1.250   \n",
       "\n",
       "      feature_56  feature_57  label  \n",
       "0             61         278      1  \n",
       "1            101        1028      1  \n",
       "2            485        2259      1  \n",
       "3             40         191      1  \n",
       "4             40         191      1  \n",
       "...          ...         ...    ...  \n",
       "4596           3          88      0  \n",
       "4597           4          14      0  \n",
       "4598           6         118      0  \n",
       "4599           5          78      0  \n",
       "4600           5          40      0  \n",
       "\n",
       "[4601 rows x 58 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "columns = [f'feature_{i}' for i in range(1, 58)] + ['label']\n",
    "spambase = pd.read_csv('spambase.data', header=None, names=columns)\n",
    "spambase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fca8e8e-87f6-4ef7-aafe-d3a11677d20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4601 entries, 0 to 4600\n",
      "Data columns (total 58 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   feature_1   4601 non-null   float64 \n",
      " 1   feature_2   4601 non-null   float64 \n",
      " 2   feature_3   4601 non-null   float64 \n",
      " 3   feature_4   4601 non-null   float64 \n",
      " 4   feature_5   4601 non-null   float64 \n",
      " 5   feature_6   4601 non-null   float64 \n",
      " 6   feature_7   4601 non-null   float64 \n",
      " 7   feature_8   4601 non-null   float64 \n",
      " 8   feature_9   4601 non-null   float64 \n",
      " 9   feature_10  4601 non-null   float64 \n",
      " 10  feature_11  4601 non-null   float64 \n",
      " 11  feature_12  4601 non-null   float64 \n",
      " 12  feature_13  4601 non-null   float64 \n",
      " 13  feature_14  4601 non-null   float64 \n",
      " 14  feature_15  4601 non-null   float64 \n",
      " 15  feature_16  4601 non-null   float64 \n",
      " 16  feature_17  4601 non-null   float64 \n",
      " 17  feature_18  4601 non-null   float64 \n",
      " 18  feature_19  4601 non-null   float64 \n",
      " 19  feature_20  4601 non-null   float64 \n",
      " 20  feature_21  4601 non-null   float64 \n",
      " 21  feature_22  4601 non-null   float64 \n",
      " 22  feature_23  4601 non-null   float64 \n",
      " 23  feature_24  4601 non-null   float64 \n",
      " 24  feature_25  4601 non-null   float64 \n",
      " 25  feature_26  4601 non-null   float64 \n",
      " 26  feature_27  4601 non-null   float64 \n",
      " 27  feature_28  4601 non-null   float64 \n",
      " 28  feature_29  4601 non-null   float64 \n",
      " 29  feature_30  4601 non-null   float64 \n",
      " 30  feature_31  4601 non-null   float64 \n",
      " 31  feature_32  4601 non-null   float64 \n",
      " 32  feature_33  4601 non-null   float64 \n",
      " 33  feature_34  4601 non-null   float64 \n",
      " 34  feature_35  4601 non-null   float64 \n",
      " 35  feature_36  4601 non-null   float64 \n",
      " 36  feature_37  4601 non-null   float64 \n",
      " 37  feature_38  4601 non-null   float64 \n",
      " 38  feature_39  4601 non-null   float64 \n",
      " 39  feature_40  4601 non-null   float64 \n",
      " 40  feature_41  4601 non-null   float64 \n",
      " 41  feature_42  4601 non-null   float64 \n",
      " 42  feature_43  4601 non-null   float64 \n",
      " 43  feature_44  4601 non-null   float64 \n",
      " 44  feature_45  4601 non-null   float64 \n",
      " 45  feature_46  4601 non-null   float64 \n",
      " 46  feature_47  4601 non-null   float64 \n",
      " 47  feature_48  4601 non-null   float64 \n",
      " 48  feature_49  4601 non-null   float64 \n",
      " 49  feature_50  4601 non-null   float64 \n",
      " 50  feature_51  4601 non-null   float64 \n",
      " 51  feature_52  4601 non-null   float64 \n",
      " 52  feature_53  4601 non-null   float64 \n",
      " 53  feature_54  4601 non-null   float64 \n",
      " 54  feature_55  4601 non-null   float64 \n",
      " 55  feature_56  4601 non-null   int64   \n",
      " 56  feature_57  4601 non-null   int64   \n",
      " 57  label       4601 non-null   category\n",
      "dtypes: category(1), float64(55), int64(2)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "#check data type\n",
    "spambase.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fcbcb22-9e0f-4953-86b5-1c48784fe7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4601 entries, 0 to 4600\n",
      "Data columns (total 58 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   feature_1   4601 non-null   float64 \n",
      " 1   feature_2   4601 non-null   float64 \n",
      " 2   feature_3   4601 non-null   float64 \n",
      " 3   feature_4   4601 non-null   float64 \n",
      " 4   feature_5   4601 non-null   float64 \n",
      " 5   feature_6   4601 non-null   float64 \n",
      " 6   feature_7   4601 non-null   float64 \n",
      " 7   feature_8   4601 non-null   float64 \n",
      " 8   feature_9   4601 non-null   float64 \n",
      " 9   feature_10  4601 non-null   float64 \n",
      " 10  feature_11  4601 non-null   float64 \n",
      " 11  feature_12  4601 non-null   float64 \n",
      " 12  feature_13  4601 non-null   float64 \n",
      " 13  feature_14  4601 non-null   float64 \n",
      " 14  feature_15  4601 non-null   float64 \n",
      " 15  feature_16  4601 non-null   float64 \n",
      " 16  feature_17  4601 non-null   float64 \n",
      " 17  feature_18  4601 non-null   float64 \n",
      " 18  feature_19  4601 non-null   float64 \n",
      " 19  feature_20  4601 non-null   float64 \n",
      " 20  feature_21  4601 non-null   float64 \n",
      " 21  feature_22  4601 non-null   float64 \n",
      " 22  feature_23  4601 non-null   float64 \n",
      " 23  feature_24  4601 non-null   float64 \n",
      " 24  feature_25  4601 non-null   float64 \n",
      " 25  feature_26  4601 non-null   float64 \n",
      " 26  feature_27  4601 non-null   float64 \n",
      " 27  feature_28  4601 non-null   float64 \n",
      " 28  feature_29  4601 non-null   float64 \n",
      " 29  feature_30  4601 non-null   float64 \n",
      " 30  feature_31  4601 non-null   float64 \n",
      " 31  feature_32  4601 non-null   float64 \n",
      " 32  feature_33  4601 non-null   float64 \n",
      " 33  feature_34  4601 non-null   float64 \n",
      " 34  feature_35  4601 non-null   float64 \n",
      " 35  feature_36  4601 non-null   float64 \n",
      " 36  feature_37  4601 non-null   float64 \n",
      " 37  feature_38  4601 non-null   float64 \n",
      " 38  feature_39  4601 non-null   float64 \n",
      " 39  feature_40  4601 non-null   float64 \n",
      " 40  feature_41  4601 non-null   float64 \n",
      " 41  feature_42  4601 non-null   float64 \n",
      " 42  feature_43  4601 non-null   float64 \n",
      " 43  feature_44  4601 non-null   float64 \n",
      " 44  feature_45  4601 non-null   float64 \n",
      " 45  feature_46  4601 non-null   float64 \n",
      " 46  feature_47  4601 non-null   float64 \n",
      " 47  feature_48  4601 non-null   float64 \n",
      " 48  feature_49  4601 non-null   float64 \n",
      " 49  feature_50  4601 non-null   float64 \n",
      " 50  feature_51  4601 non-null   float64 \n",
      " 51  feature_52  4601 non-null   float64 \n",
      " 52  feature_53  4601 non-null   float64 \n",
      " 53  feature_54  4601 non-null   float64 \n",
      " 54  feature_55  4601 non-null   float64 \n",
      " 55  feature_56  4601 non-null   int64   \n",
      " 56  feature_57  4601 non-null   int64   \n",
      " 57  label       4601 non-null   category\n",
      "dtypes: category(1), float64(55), int64(2)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "#convert label column to categorical\n",
    "spambase['label'] = spambase['label'].astype('category')\n",
    "\n",
    "#check data type\n",
    "spambase.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93e9d3f-ed31-44ec-9c77-bb6d648220ea",
   "metadata": {},
   "source": [
    "###   Task 3 : Train/Test Split and SVM Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2024974-b56d-47b2-90e5-606ddec8f787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (3680, 57), Test data shape: (921, 57)\n"
     ]
    }
   ],
   "source": [
    "#split dataset\n",
    "X=spambase.iloc[:, :-1]\n",
    "y=spambase['label']\n",
    "\n",
    "#split into training(80) and testing(20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'Training data shape: {X_train.shape}, Test data shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "434b68c8-f743-4f54-9d3d-5c85ab689487",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize the data for SVM\n",
    "#We use StandardScaler to transform the features such that they have a mean of 0 and a standard deviation of 1.\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled =scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca33ac57-59a2-441a-a1ab-7bb29b25a59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train SVM model\n",
    "svm = SVC(kernel='rbf',random_state=42)\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "#predict\n",
    "y_pred = svm.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5efe2479-3990-44c7-800e-b45024e54022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[513  18]\n",
      " [ 42 348]]\n",
      "Accuracy:  0.9348534201954397\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nThe confusion matrix shows how well the model distinguishes between spam and non\\x02spam.\\nAccuracy is a measure of the model's overall performance.\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate model\n",
    "cm= confusion_matrix(y_test,y_pred)\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "\n",
    "print('Confusion matrix:\\n', cm)\n",
    "print('Accuracy: ', accuracy)\n",
    "\n",
    "\n",
    "'''\n",
    "The confusion matrix shows how well the model distinguishes between spam and non\u0002spam.\n",
    "Accuracy is a measure of the model's overall performance.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137f1396-c743-4903-bfd0-1a8fc0311426",
   "metadata": {},
   "source": [
    "###   Task 4 : Dimensionality Reduction Using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13c39d9e-68a0-4c48-ba2d-d0c6d5a41d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original feature shape: (3680, 57), Reduced feature shape: (3680, 29)\n"
     ]
    }
   ],
   "source": [
    "# Apply PCA to reduce to 29 features\n",
    "pca = PCA(n_components=29)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "print(f'Original feature shape: {X_train.shape}, Reduced feature shape: {X_train_pca.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32398a2a-a70e-4a38-ae85-40914a9e3f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrain model based on PCA reduced data\n",
    "svm_pca = SVC(kernel='rbf',random_state=42)\n",
    "svm_pca.fit(X_train_pca, y_train)\n",
    "\n",
    "#predict\n",
    "y_pred_pca = svm_pca.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3bc8ea9b-f1f7-4ad0-a1f0-db94fbf163c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix after PCA:\n",
      " [[512  19]\n",
      " [ 44 346]]\n",
      "Accuracy after PCA:  0.9315960912052117\n"
     ]
    }
   ],
   "source": [
    "#Evaluate model of PCA\n",
    "cm_pca= confusion_matrix(y_test,y_pred_pca)\n",
    "accuracy_pca = accuracy_score(y_test,y_pred_pca)\n",
    "\n",
    "print('Confusion matrix after PCA:\\n', cm_pca)\n",
    "print('Accuracy after PCA: ', accuracy_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b18265-9011-4a33-a26b-b7da73fb82f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
